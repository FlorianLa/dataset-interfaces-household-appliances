## A Dataset and Machine Learning Approach to Classify and Augment Interface Elements of Household Appliances to Support People with Visual Impairment
ACM Link, direkt Paper link, direkt video Link, Image?

### General information and Disclaimer
This repository (or rather the releases of this repository) are mirrored on Zenodo.org. Link:
<br>
The Dataset itself can be found in the latest release LINK 
<br>
Further, this repository contains an example application, instructions on how to create and label more images, and a trained neuronal network as detailed below.

### Dataset
The dataset consists of 13 with 75,551 manually labled interface elements. The elements are differentiated into the five categories *Knob*, *Slider*, *Toggle*, *PushButton*, and *Touchbutton*. More details regarding the images, i.e., light situation, type of the household appliance, model (if availiable), and other data is listed in a separate File.

### Example Application
needs Computer and Webcam, runs on python XX, labels things in webcam image, can be customized.

### Extending the Dataset
use lableimg, phythonscript for video -> image, see video instructions and example video.

### Neuronal Network
Yolov5s model, code from HERE adjusted, trained, etc.